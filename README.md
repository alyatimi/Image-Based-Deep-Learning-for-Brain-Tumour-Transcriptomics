# ğŸ§  Saliency-Guided CNN for Brain Tumor Classification from Transcriptomic Images

This repository implements a pipeline that transforms single-cell RNA sequencing (scRNA-seq) data into RGB images using dimensionality reduction and spectral mapping. A ResNet-18 CNN is trained to classify brain tumor subtypes, and saliency maps are used for model interpretability.

---

## ğŸ“‚ Project Structure

.
â”œâ”€â”€ data/ # Raw .h5ad transcriptomic files
â”‚ â”œâ”€â”€ GSE85217_data.h5ad # Dataset with 28 tumor subtypes
â”‚ â””â”€â”€ Smartseq2_upperlim_gbm_data.h5ad # GBM-specific dataset
â”œâ”€â”€ benchmarking/ # Generated RGB images, organized by class
â”œâ”€â”€ pre_dataFix.py # Preprocessing: embeddings â†’ RGB images
â”œâ”€â”€ cnn_model.py # CNN training and evaluation
â”œâ”€â”€ generate_saliency.py # Saliency map computation
â”œâ”€â”€ training_history.png # Loss plots
â”œâ”€â”€ Figure_*.png # Confusion matrices, saliency, heatmaps
â””â”€â”€ README.md # Project documentation


---

## ğŸ§¬ Datasets

- **GSE85217**  
  28 annotated brain tumor subtypes; preprocessed from `.h5ad`.

- **Smartseq2 GBM**  
  GBM subtype expression profiles labeled via `tumour name`.

---

## âš™ï¸ Installation

Clone the repo and install dependencies:

```bash
git clone https://github.com/yourusername/tumor-classification-cnn.git
cd tumor-classification-cnn
pip install -r requirements.txt
ğŸ”„ Preprocessing Pipeline (pre_dataFix.py)

Transforms gene expression data into interpretable RGB image format.

Steps:

Load .h5ad file using Scanpy

Apply PCA (50 components), then UMAP and t-SNE

Normalize and map:

t-SNE â†’ Red

PCA â†’ Green

UMAP â†’ Blue

Render each cell to a 128Ã—128 RGB image

Save by class in /benchmarking/

ğŸ§  Model Training (cnn_model.py)

Model: ResNet-18 (ImageNet-pretrained)

Loss: CrossEntropy

Optimizer: Adam (lr = 1e-4)

Cross-validation: 5-fold stratified

Input: RGB images (128Ã—128)

Batch size: 32

Epochs: 5

ğŸ“Š Metrics

Accuracy

Precision

Recall

F1-score

Macro AUC (OvR)

ğŸ” Saliency Maps (generate_saliency.py)

Visualize what the model "sees" in each tumor image.

Loads trained model_final.pth

Computes gradients w.r.t. input

Generates and saves saliency maps per class

Output files: Figure_Saliency_1.png, Figure_Saliency_2.png, etc.

ğŸ“ˆ Sample Outputs

training_history.png â€“ Loss per fold

Figure_combined_tumor.png â€“ Tumor-type pixel map

confusion_matrix_avg.png â€“ Averaged performance matrix

Figure_Saliency_*.png â€“ Class-wise saliency interpretation

ğŸ§ª Statistical Testing

Wilcoxon Signed-Rank Test used to compare ResNet-18 vs. EfficientNet

Result: p = 0.7500 â†’ No statistically significant difference

Conclusion: ResNet-18 performs comparably with less computational overhead
